data_folder: "../dataset"
download: true
tokenizer: "distilbert-base-uncased"
dataset: "librispeech"
batch_size: 2
epochs: 10
warm_up_epochs: 3
stepsize: 1
n_fft:  1200
n_mels: 256
train_split: "train-clean-360"
valid_split: "dev-clean"
test_split: "test-clean"
embed_dim: 256
weight_decay: 1e-2
lr: 1e-5
patience: 2
factor: 0.7
cp_path: "checkpoints/librispeech360-clap-pretrain-both-pretrain.pt"
device: "cuda:1"
beta_1: 0.9
beta_2: 0.999
eps: 1e-9
